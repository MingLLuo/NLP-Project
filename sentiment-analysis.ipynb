{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "## data with imdb-movie\n",
    "## https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis\n",
    "basepath = \"\"\n",
    "movie_path = basepath + \"movie.csv\"\n",
    "movie_df = pd.read_csv(movie_path)\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after data downloaded\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import string\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_imdb(data_dir, train):\n",
    "    \"\"\"读取IMDb评论数据集文本序列和标签\"\"\"\n",
    "    \"\"\"分别读取训练集与测试集\"\"\"\n",
    "    data, labels = [], []\n",
    "    for label in ('pos', 'neg'):\n",
    "        folder_name = os.path.join(data_dir, 'train' if train else 'test', label)\n",
    "        print(folder_name)\n",
    "        for file in os.listdir(folder_name):\n",
    "          with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "              review = f.read().decode('utf-8').replace('\\n', '')\n",
    "              data.append(review)\n",
    "              labels.append(1 if label == 'pos' else 0)\n",
    "    return data, labels\n",
    "\n",
    "#使用类的方式避免重复运算\n",
    "class Vocab:\n",
    "    #min_freq：把出现次数少于min_freq的低频率词元视为相同的未知词元视为'<unk>'\n",
    "    def __init__(self, tokens=[], min_freq=0):\n",
    "        # 展开多维的token列表\n",
    "        if tokens and isinstance(tokens[0], list):\n",
    "            tokens = [token for line in tokens for token in line]\n",
    "        # 计算token中对应数据的出现次数，从大到小\n",
    "        counter = collections.Counter(tokens)\n",
    "        self.freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                  reverse=True)\n",
    "        # The list of unique tokens\n",
    "        self.index_to_token = sorted([token for token, freq in self.freqs \n",
    "                                      if freq >= min_freq]) + ['<unk>']\n",
    "        self.token_to_index = {token: idx\n",
    "                             for idx, token in enumerate(self.index_to_token)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            # if not exist '<unk>'\n",
    "            return self.token_to_index.get(tokens, self.token_to_index['<unk>'])\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if isinstance(indices, list):\n",
    "            return [self.index_to_token[int(index)] for index in indices]\n",
    "        return self.index_to_token[indices]\n",
    "\n",
    "def token_nize(sentence_list):\n",
    "  wordss = []\n",
    "  for s in sentence_list:\n",
    "    words = s.split(\" \")\n",
    "    words = [w.strip(string.punctuation) for w in words]\n",
    "    wordss.append(words)\n",
    "  return wordss\n",
    "\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"Truncate or pad sequences.\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # Truncate\n",
    "    return line + [padding_token] * (num_steps - len(line))  # Pad\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"构造一个PyTorch数据迭代器。\"\"\"\n",
    "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def load_data(batch_size, num_steps=500):\n",
    "    imdb_data_dir = \"aclImdb\"\n",
    "    imdb_train_data = read_imdb(imdb_data_dir, True)\n",
    "    imdb_train = pd.DataFrame([imdb_train_data[0], imdb_train_data[1]]).T\n",
    "    imdb_train.columns = ['sentence','label']\n",
    "    imdb_test_data = read_imdb(imdb_data_dir, False)\n",
    "    imdb_test = pd.DataFrame([imdb_test_data[0], imdb_test_data[1]]).T\n",
    "    imdb_test.columns = ['sentence','label']\n",
    "    \n",
    "    movie_train, movie_test = train_test_split(movie_df, test_size=0.5, random_state=0)\n",
    "    movie_train.columns = ['sentence','label']\n",
    "    movie_test.columns = ['sentence','label']\n",
    "    \n",
    "    train_data = pd.concat([movie_train, imdb_train])\n",
    "    test_data = pd.concat([movie_test, imdb_test])\n",
    "    train_data['label'] = train_data['label'].astype(int)\n",
    "    test_data['label'] = test_data['label'].astype(int)\n",
    "    \n",
    "    train_tokens = token_nize(train_data[\"sentence\"])\n",
    "    test_tokens = token_nize(test_data[\"sentence\"])\n",
    "    vocab = Vocab(train_tokens, min_freq=5)\n",
    "    train_features = torch.tensor([truncate_pad(\n",
    "        vocab[line], num_steps, vocab['<pad>']) for line in train_tokens])\n",
    "    test_features = torch.tensor([truncate_pad(\n",
    "        vocab[line], num_steps, vocab['<pad>']) for line in test_tokens])\n",
    "    train_iter = load_array((train_features, torch.tensor(train_data[\"label\"].values)), batch_size)\n",
    "    test_iter = load_array((test_features, torch.tensor(test_data[\"label\"].values)), batch_size, is_train=False)\n",
    "    return train_iter, test_iter, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb/train/pos\n",
      "aclImdb/train/neg\n",
      "aclImdb/test/pos\n",
      "aclImdb/test/neg\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "batch_size = 64\n",
    "train_iter, test_iter, vocab = load_data(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7b695a2f70> <torch.utils.data.dataloader.DataLoader object at 0x7f7b695a2a30> <__main__.Vocab object at 0x7f7b6a1af3d0>\n"
     ]
    }
   ],
   "source": [
    "print(train_iter, test_iter, vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
